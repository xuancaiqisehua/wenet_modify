accum_grad: 16
cif_predictor_conf:
  idim: 384
  l_order: 1
  r_order: 1
  tail_threshold: 0.0 #0.45
  threshold: 1.0
cmvn_file: exp/paraformer/global_cmvn
dataset_conf:
  batch_conf:
    batch_size: 16
    batch_type: dynamic
    max_frames_in_batch: 47000
  fbank_conf:
    dither: 1.0
    frame_length: 25
    frame_shift: 10
    num_mel_bins: 80
  filter_conf:
    max_length: 4000
    min_length: 10
    token_max_length: 200
    token_min_length: 1
  noise_aug: true
  noise_conf:
    max_snr: 15
    min_snr: 5
    noiseLst: data/train/noise_500.lst
    noise_shuffle_size: 1000
  resample_conf:
    resample_rate: 16000
  reverb_source: data/rirs/lmdb_simu/
  shuffle: true
  shuffle_conf:
    shuffle_size: 9500
  sort: false
  sort_conf:
    sort_size: 2000
  spec_aug: true
  spec_aug_conf:
    max_f: 10
    max_t: 25
    num_f_mask: 2
    num_t_mask: 4
  spec_sub: true
  spec_sub_conf:
    max_t: 30
    num_t_sub: 3
  speed_perturb: true
decoder: transformer
decoder_conf:
  attention_heads: 4
  dropout_rate: 0.1
  input_layer: none
  linear_units: 2048
  num_blocks: 6
  positional_dropout_rate: 0.1
  self_attention_dropout_rate: 0.0
  src_attention_dropout_rate: 0.0
encoder: conformer
encoder_conf:
  activation_type: swish
  attention_dropout_rate: 0.0
  attention_heads: 4
  causal: true
  cnn_module_kernel: 15
  cnn_module_norm: layer_norm
  dropout_rate: 0.1
  input_layer: conv2d
  linear_units: 2048
  normalize_before: true
  num_blocks: 12
  output_size: 384
  pos_enc_layer_type: rel_pos
  positional_dropout_rate: 0.1
  selfattention_layer_type: rel_selfattn
  use_cnn_module: true
  use_dynamic_chunk: true
  use_dynamic_left_chunk: false
grad_clip: 5
input_dim: 80
is_json_cmvn: true
lfmmi_dir: ''
log_interval: 100
max_epoch: 360
model_conf:
  ctc_weight: 0.3
  length_normalized_loss: false
  lsm_weight: 0.1
  predictor_weight: 1.0
model_interval: 40000
optim: adam
optim_conf:
  lr: 0.001
output_dim: 1751
paraformer: true
scheduler: warmuplr
scheduler_conf:
  warmup_steps: 5000
